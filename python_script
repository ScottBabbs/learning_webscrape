from urllib import urlopen as uReq
from bs4 import BeautifulSoup as soup

myUrl = 'https://www.newegg.com/Video-Cards-Video-Devices/Category/ID-38?Tpk=graphics%20cards'

#opening up connection...
uClient = uReq(myUrl)

#grabbing the page...
pageHtml = uClient.read()

#closing the connection
uClient.close()

#html parsing using BeautifulSoup as Soup from pageHtml
pageSoup = soup(pageHtml, "html.parser")

#grabs each product
containers = pageSoup.findAll("div",{"class":"item-container"})

filename = "products.csv"
f = open(filename, "w")

headers = "brand, productName, shipping\n"


f.write("headers")

#this loop defines brand, product name, and shipping costs, recieves data from website, and write it to a csv file

for container in containers:
	brand = container.div.div.a.img["title"]

	titleContainer = container.findAll("a", {"class":"item-title"})
	productName = titleContainer[0].text

	shippingContainer = container.findAll("li",{"class":"price-ship"})
	shipping = shippingContainer[0].text.strip()


	print("brand: " + brand)
	print("productName: " + productName)
	print("shipping: " + shipping)

	f.write(brand + ", " + productName.replace(",", "|") + ", " + shipping + "\n")

f.close()
